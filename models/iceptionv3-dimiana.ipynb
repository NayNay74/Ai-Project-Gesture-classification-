{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\nIMG_SIZE_INCEPTION = 299\nBATCH_SIZE_INCEPTION = 16\n\ntrain_tf_inception = transforms.Compose([\n    transforms.Resize((IMG_SIZE_INCEPTION, IMG_SIZE_INCEPTION)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\nval_tf_inception = transforms.Compose([\n    transforms.Resize((IMG_SIZE_INCEPTION, IMG_SIZE_INCEPTION)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\ntrain_dataset_inception = datasets.ImageFolder(\n    root=f\"{DATA_DIR}/train\",\n    transform=train_tf_inception\n)\n\nval_dataset_inception = datasets.ImageFolder(\n    root=f\"{DATA_DIR}/val\",\n    transform=val_tf_inception\n)\n\ntest_dataset_inception = datasets.ImageFolder(\n    root=f\"{DATA_DIR}/test\",\n    transform=val_tf_inception\n)\n\ntrain_loader_inception = DataLoader(\n    train_dataset_inception,\n    batch_size=BATCH_SIZE_INCEPTION,\n    shuffle=True,\n    num_workers=NUM_WORKERS\n)\n\nval_loader_inception = DataLoader(\n    val_dataset_inception,\n    batch_size=BATCH_SIZE_INCEPTION,\n    shuffle=False,\n    num_workers=NUM_WORKERS\n)\n\ntest_loader_inception = DataLoader(\n    test_dataset_inception,\n    batch_size=BATCH_SIZE_INCEPTION,\n    shuffle=False,\n    num_workers=NUM_WORKERS\n)\n\nprint(\"Inception classes:\", train_dataset_inception.classes)\nprint(\"Number of classes:\", len(train_dataset_inception.classes))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ninception = models.inception_v3(\n    weights=models.Inception_V3_Weights.IMAGENET1K_V1,\n    aux_logits=True\n)\n\nfor p in inception.parameters():\n    p.requires_grad = False\n\nfor name, p in inception.named_parameters():\n    if any(k in name for k in [\"Mixed_6\", \"Mixed_7\"]):\n        p.requires_grad = True\n\nnum_classes = len(train_dataset_inception.classes)\n\n# Replace classifier\ninception.fc = nn.Sequential(\n    nn.Linear(inception.fc.in_features, 512),\n    nn.ReLU(),\n    nn.Dropout(0.4),\n    nn.Linear(512, num_classes)\n)\n\nfor p in inception.fc.parameters():\n    p.requires_grad = True\n\ninception = inception.to(DEVICE)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n\noptimizer = optim.AdamW(\n    filter(lambda p: p.requires_grad, inception.parameters()),\n    lr=2e-4,          \n    weight_decay=1e-4\n)\n\nscheduler = optim.lr_scheduler.CosineAnnealingLR(\n    optimizer,\n    T_max=18\n)\n\nprint(\"InceptionV3 ready\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"EPOCHS = 18\nbest_val_acc = 0.0\n\nfor epoch in range(EPOCHS):\n\n    # -------- Training --------\n    inception.train()\n    train_correct = 0\n    train_total = 0\n    train_loss = 0.0\n\n    for images, labels in train_loader_inception:\n        images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n        optimizer.zero_grad()\n\n        outputs, aux_outputs = inception(images)\n\n        loss_main = criterion(outputs, labels)\n        loss_aux  = criterion(aux_outputs, labels)\n        loss = loss_main + 0.4 * loss_aux\n\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item() * labels.size(0)\n        preds = outputs.argmax(1)\n        train_correct += (preds == labels).sum().item()\n        train_total += labels.size(0)\n\n    train_acc = train_correct / train_total\n    train_loss /= train_total\n\n    # -------- Validation --------\n    inception.eval()\n    val_correct = 0\n    val_total = 0\n\n    with torch.no_grad():\n        for images, labels in val_loader_inception:\n            images, labels = images.to(DEVICE), labels.to(DEVICE)\n\n            outputs = inception(images)  \n            preds = outputs.argmax(1)\n            val_correct += (preds == labels).sum().item()\n            val_total += labels.size(0)\n\n    val_acc = val_correct / val_total\n\n    scheduler.step()\n\n    print(\n        f\"[Inception] Epoch {epoch+1}/{EPOCHS} | \"\n        f\"Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f}\"\n    )\n\n    # -------- Save Best --------\n    if val_acc > best_val_acc:\n        best_val_acc = val_acc\n        torch.save(inception.state_dict(), \"inception_best.pth\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"inception.load_state_dict(\n    torch.load(\"inception_best.pth\", map_location=DEVICE)\n)\ninception.eval()\nprint(\"InceptionV3 weights loaded\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport numpy as np\n\ninception.eval()\n\ncriterion = torch.nn.CrossEntropyLoss()\n\ntest_correct = 0\ntest_total = 0\ntest_loss = 0.0\n\ninception_all_preds = []\ninception_all_labels = []\n\nwith torch.no_grad():\n    for images, labels in test_loader_inception:\n        images = images.to(DEVICE)\n        labels = labels.to(DEVICE)\n\n        outputs = inception(images)\n        loss = criterion(outputs, labels)\n\n        preds = outputs.argmax(1)\n\n        test_loss += loss.item() * labels.size(0)\n        test_correct += (preds == labels).sum().item()\n        test_total += labels.size(0)\n\n        inception_all_preds.extend(preds.cpu().numpy())\n        inception_all_labels.extend(labels.cpu().numpy())\n\ntest_acc = test_correct / test_total\ntest_loss /= test_total\n\nprint(f\"InceptionV3 Test Accuracy: {test_acc:.4f}\")\nprint(f\"InceptionV3 Test Loss: {test_loss:.4f}\")\n\ninception_test_acc = test_acc","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"InceptionV3 — Classification Report (Test Set)\")\nprint(\n    classification_report(\n        inception_all_labels,\n        inception_all_preds,\n        target_names=class_names,\n        digits=4\n    )\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\n\nclass_names = train_dataset_inception.classes\n\ncm = confusion_matrix(inception_all_labels, inception_all_preds)\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(\n    cm,\n    cmap=\"Blues\",\n    xticklabels=class_names,\n    yticklabels=class_names,\n    annot=False\n)\n\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"InceptionV3 — Confusion Matrix (Test Set)\")\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\n\nwith open(\"class_names.json\", \"w\") as f:\n    json.dump(train_dataset_inception.classes, f)\n\nprint(\"Saved class_names.json\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}